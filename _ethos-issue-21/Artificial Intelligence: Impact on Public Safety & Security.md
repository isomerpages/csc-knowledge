---
title: "Artificial Intelligence: Impact on Public Safety & Security"
permalink: /ethos-issue-21/artificial-intelligence-impact-on-public-safety-and-security/
description: ""
variant: markdown
---
<style>

.back a
{
	color: #9f2943;
	font-weight: bold;
}

#banner img
{
	width:100%;
}
	
.author
{
border-bottom: 1px solid black;
margin-top:40px;
padding-bottom:30px;
border-top: 1px solid black;	

}

.author p {
	font-size: 0.9em;
	line-height:24px !important;
	}	

.break
{
   border-top: 1px solid  black;
   border-bottom: 1px solid black;
	 padding:20px;
	text-align:center;
	margin-top:50px;
}
	
.break1
{
font-family: Georgia;
	font-size:20px;
	font-style: italic;
	font-weight: bold;
}

.boxheader {
	color: white !important;
	}	

.containerbox {
	background-color: #284965;
	border-radius: 10px;
	padding: 5%;
	margin-top: 5%;
	color: white;
	
	}	
	
.containerbox h3{
	color: white;
	}	

li {
	font-size: 15px !important;
	
	}	

</style>

<em><small>ETHOS Issue 21, July 2019</small></em>
<img src="/images/Cropped_images/Ethos_Issue_21/21_Banner_Artificial_Intelligence_ImpactOnPublic.jpg">



<p>In the American television drama Person of Interest, “The Machine” is an advanced
computer system that functions as a vigilante crime-fighting tool: it employs pattern recognition to stop crimes before they materialise. This premise—crime prevention with the help of Artificial
Intelligence (AI)—is no longer so far-fetched.</p>

<p>An increasingly sophisticated technology, AI could support preventive policing to bring about a safer community. But are there any downsides we need to be aware of? What are AI’s possibilities as well as potential risks in the context of public safety and security, and what can we do to mitigate
potential downsides?</p>

<h3>AI Enhances Operational Effectiveness</h3>

<p>As a set of technologies that simulate human traits such as knowledge, reasoning, problem solving, perception, learning and planning,<a href="#notes"><sup>1</sup></a> AI can enhance operational
effectiveness through <strong>automation</strong> and <strong>augmentation</strong>. When combined, they complement human expertise, producing faster and better results. While AI can
spot patterns that may escape the naked eye, humans can contextualise data insights and decision-making with intuition and experience.</p>

<p>The automation of data-heavy processing tasks, from visual inspections of public spaces to interpreting security video footage, can help to overcome resource constraints. This frees up scarce human capacity for higher-value work and more complex problem-solving, boosting
workplace productivity and engagement.</p>

<p>Machine self-learning capabilities have predictive and prescriptive uses. AI creates new sense-making possibilities by quickly generating insights through deeper analysis of data.</p>

<div class="break">

<p class="break1">
While AI augments capability, it cannot entirely replace humans.
</p>

</div>

<h3>Automating the Home Team’s Operational Capabilities</h3>

<p>In Singapore, AI has already found its way into a variety of Home Team<a href="#notes"><sup>2</sup></a> border security and homeland security applications. AI-driven perception,
processing, and analysis are essential for collecting, sorting, and interpreting data to better inform human decision-making. A leading AI technology now being deployed is machine-learning
computer vision technology. AI-backed biometric systems have also become more powerful than ever in spotting patterns in human physiology.</p>

<p>AI—at the intersection of machine learning and robotics—has also given rise to autonomous systems that can tackle more challenging tasks in a wider range of environments. While sensors can provide data inputs to systems, the AI element helps to filter and make sense of data, and can recommend particular actions. Unmanned Aerial Vehicles (UAVs) are robotic autonomous systems that give our officers a bird’s-eye view of a situation, so they can make better ground decisions. In the future, the UAVs could incorporate AI in the following forms:</p>

<p>a. "Computer Vision &amp; Learning”—the
ability to analyse visual input; <br>
b. "Machine Perception”—the ability to
processing input from a variety of
sensors; and <br>
c. "Motion Planning”—the ability to break
down a desired path into smaller,
more manageable segments.</p>

<p>The Singapore Civil Defence Force
(SCDF) has deployed UAVs in monitoring
activities outdoors and in public spaces,
such as fire tracking, surveillance,
and Search and Rescue missions. The
integration of these systems complements
current operations and aims to improve
operational effectiveness. An example
is SCDF’s use of a Red Rhino Robot (or
3R) for autonomous fire detection, with
an auto heat-seeking mechanism to
help find heat sources. This robot can
potentially reduce a traditional four-man
crew to a team of three, and penetrate
far deeper into the seat of fire without
risking a human firefighter.</p>

<h3>Augmenting the Home
Team’s Operational
Capabilities</h3>

<p>UAVs also augment police neighbourhood
patrols. The UAVs can transmit a live
aerial video feed to a Police Operations
Command Centre (POCC), facilitating
their dispatch to the crime scene.
Advanced sensors, intelligent autonomous
navigation and mapping algorithms
may be progressively added to these
UAVs to improve obstacle detection
and avoidance.&nbsp;<img title="Gallery of photos" style="float: right;" src="/images/Ethos_Images/Ethos_Issue_21/Gallery_Of_Photos.jpg" alt="Gallery of photos"></p>

<p style="text-align: left;">The Home Team is well aware that AI is
not a magical silver bullet that will solve
all problems: different operations call
for different degrees of technological
intervention. While AI augments capability,
it cannot entirely replace humans. The
use of UAVs, for example, enhances
the present force’s capabilities and
effectiveness, with the same manpower
resources. But our frontline officers remain
relevant to the community they serve
in. Officers bring a human touch, and
an assuring sense of safety and security
to the community. Human touchpoints
that communities value cannot easily
be replaced by AI.</p>


<p class="small-text text">Iris scans were introduced on a trial basis at the Woodlands Checkpoint in July 2018, enhancing the existing network of cameras with the facial recognition capabilities of the Automated Biometric and Behavioural Screening Suite. </p>

<div class="containerbox">
<h3 class="title">AI Integration in Singapore's Border Security Operations</h3>

<p class="text">Iris scans were introduced on a trial basis at the Woodlands Checkpoint in July 2018, enhancing the existing network of cameras with the facial recognition capabilities of the Automated Biometric and Behavioural Screening Suite.The Immigration &amp; Checkpoints Authority plans to roll out
the Suite progressively at all checkpoints.</p>

<p class="text">Video analytics and screening capabilities identify suspicious objects and individuals, and
conduct quick biometric identity verification. This reduces manpower requirements and also increases operational effectiveness. Since its introduction, the system has swiftly detected foreigners wanted for offences such as overstaying.</p>
</div>



<div class="containerbox">
<h3 class="title">Case Study: Emergency Management</h3>
<p class="small-text text">The Ministry of Home Affairs
uses UAVs (also known as
drones) to conduct aerial
surveillance for forested
operations, fire management
and crowd monitoring for
mass public events such as the
New Year’s Eve Countdown.</p>

<p class="text">The Ministry of Home Affairs
uses UAVs (also known as
drones) to conduct aerial
surveillance for forested
operations, fire management
and crowd monitoring for
mass public events such as the
New Year’s Eve Countdown.
Equipped with high-definition
cameras that transmit clear
images of people and objects
on the ground, the drones use
thermal-imaging capabilities
to help identify human heat
signatures—a boon for spotting
suspects in densely-forested
areas, especially at night.</p>

<p class="text">Since December 2016, the
drones have helped police to
nab three criminals conducting
illegal activities in the forest;
they have also monitored major
pipelines, and even traffic
congestion at checkpoints. In
October 2018, police officers
caught 125 illegal immigrants
via night-time drone operations
in the western and northern
parts of Singapore.</p>
</div>

<h3>Potential for Exploitation</h3>

<p>Any emerging technology is a double-edged
sword, with potential for abuse
by malicious actors. Automation
and augmentation through AI have
contributed to such widely reported
abuses as cybersecurity breaches and
fake news distribution. Understanding
how malicious agents can manipulate
AI technologies to their advantage is
crucial in mitigating potential threats.</p>


<br>
<h4>The Thinking Malware</h4>
<p>In 2017, 62% of the attendees at Black
Hat USA 2017—the world’s leading
information security conference—said
they believe artificial intelligence will be
used for cyberattacks in the near future.<a href="#notes"><sup>3</sup></a>
In fact, this has already happened. IBM
security researches have uncovered a new
breed of AI-powered cyber-attacks that
can automatically target vulnerabilities
with greater speed and accuracy.<a href="#notes"><sup>4</sup></a>
Deep Locker, a recent product of IBM
Research, demonstrates how AI-powered
malware is highly successful at evading
traditional detection.<a href="#notes"><sup>5</sup></a> Automated to
attack with peak effectiveness and with
self-learning capabilities, each attempt
becomes more effective than the last.</p>

<p>The first observed example of an AI-backed
malware hack was executed
in 2017, on an India-based company.<a href="#notes"><sup>6</sup></a>
Embedded algorithms allowed the
software to first observe and figure out
the typical user’s network behaviour,
and then mimick their digital footprints
to evade surveillance detection long
enough to complete the hack. Data
breaches may now go undetected for
longer as AI-powered attacks emulate
this detection-evading mechanism.</p>


<br>
<h4>The Role in Fake News</h4>
<p>The ease of access to emerging technologies
means AI is as readily available for
use by malicious actors as by proper
authorities. Deliberate online falsehoods,
the online proliferation of false stories
often embedded with social, economic
and political biases with the malicious
intent of misleading audiences for gain,
are becoming increasingly common. The
generation of these increasingly realistic
falsehoods suggest how AI could be
manipulated to fool more people more
effectively and quickly.</p>

<p>Neural networks underpinning AI
technologies have augmented multimedia
editing. Almost perfect image and video
manipulations are now achievable, creating
photo-realistic images and mimicking
voices seamlessly. These are known
as “Deep Fakes”.<a href="#notes"><sup>7</sup></a> Discerning between
what is real and fake online is no longer
straightforward. A viral video of Barack
Obama, where the former US President
is seen and heard using expletives,
was made using Adobe’s After Effects
software and the AI face-swapping
tool FakeApp. The fake footage was
swiftly disseminated across many virtual
platforms, garnering over 3.7 million
views within a week.<a href="#notes"><sup>8</sup></a> This shows just
how attention-grabbing and persuasive
fakes can be.</p>

<div class="break">

<p class="break1">
At present, even an AI of tremendous power will not be able to determine outcomes in a
complex social system, the outcomes are too complex—even without allowing for free will by
sentient agents...Strategy that involves humans, no matter that they are assisted by modular AI and
fight using legions of autonomous robots, will retain its inevitable human flavor.<a href="#notes"><sup>9</sup></a>
</p>

<p style="font-weight: bold; letter-spacing: 1px; text-align: right;" class="small-text">—Kareem Ayoub and Kenneth Payne</p>

</div>

<h3>Strengthening Our Resilience for The Future: AI and Beyond </h3>


<br>
<h4>Cybersecurity</h4>
<p>For all the inherent risks AI presents
in self-mutating malware, the answer
might ironically lie in harnessing the
power of AI itself to strengthen existing
cybersecurity setups. SparkCognition,
a US-based company, developed an
entirely AI-based solution called Deep
Armor in 2017.<a href="#notes"><sup>10</sup></a> It is the first cognitive
antivirus software that leverages AI to
identify mutating online viruses and
detect malware approaches, including
advanced malware masking techniques,
and stepping up against more sophisticated
cyberattacks. AI can therefore be tapped
to upgrade cybersecurity capabilities
not only in detection and response, but
also preventive defence.</p>

<p>In parallel, a deliberate talent strategy
will be important, to recruit and deploy
those with the expertise to work with
AI to boost cybersecurity. For example,
Thailand’s government agencies have
begun deploying sensors running AI
algorithms, incorporating predictive
analytics in cyber network monitoring
systems.<a href="#notes"><sup>11</sup></a> At the same time, a new digital
forensics team is being developed to
specifically investigate digital evidence
from cyber-attacks.<a href="#notes"><sup>12</sup></a> These projects
accompany plans to raise existing
employees’ digital literacy, while looking
overseas to recruit experts. Such a move
aims to combine AI-enabled prevention
and protection systems’ algorithmic
decision-making, with flexible human
interaction and supervision.</p>


<br>
<h4>Dealing with Fake News</h4>
<p>Research is already being carried
out on how to deploy AI in detecting
falsehoods. The machine can be trained
to analyse text and determine how likely
it is that a particular message is a real
communication from an actual person,
or a mass-distributed solicitation.<a href="#notes"><sup>13</sup></a>
Building on a similar type of text analysis
to spam-fighting, AI systems are also
trained to evaluate h ow well a post’s
text, or a headline, compares with the
actual content of an article someone is
sharing online. Another method could
examine similar articles to see whether
other news media have differing facts.
Similar systems can identify specific
accounts and source websites that
spread fake news.</p>

<p>However, mitigation measures must go
beyond technology: the response needs
to be all-rounded, involving citizens and
public-private collaborations. To inoculate
the community against falsehoods,
Singapore government agencies such
as MCI<a href="#notes"><sup>14</sup></a> and IMDA have begun efforts to
promote better media literacy<a href="#notes"><sup>15</sup></a> through
educational forums, training users to
critically evaluate and independently
report suspicious information.<a href="#notes"><sup>16</sup></a></p>


<br>
<h4>A Broader Perspective</h4>
<p>From the security perspective, a multi-agency
effort is needed to establish a
framework so that agencies understand
the appropriate responses to different
risks. Relevant agencies are also working
together to anticipate and identify
emerging security risks linked to such
technology adoption, and to build up
capabilities to address these risks.</p>

<p>As we gain a better understanding of
AI, we will be better at mitigating its
dangers. Exciting times are ahead—we
have entered a brave new world.</p>

<div class="author">

<h6>ABOUT THE AUTHORS</h6>


<p class="small-text"><strong>Rahul Daswani</strong>&nbsp;led the Futures team at the Ministry of Home Affairs. Previously a Senior Strategist at the Centre for Strategic Futures, he has
            also served at SkillsFuture Singapore.</p>
<p class="small-text">He is now Assistant Director, Open Government Products at GovTech.</p>
<p class="small-text"><strong>Jevon Tan</strong> is part of a team from the Defence Science &amp; Technology Agency (DSTA) embedded in National Security Coordination Secretariat (NSCS), where he identifies risks and threats relating to emerging technologies. Prior to joining NSCS, he was involved in telecommunications acquisition projects and master-planning in DSTA.</p>


</div>

<h6><a name="notes"></a>NOTES</h6>

<ol>
<li class="small-text">Personal Data Protection Commission,
    Infocomm Media Development Authority,
    Singapore, “A Proposed Model Artificial
    Intelligence Governance Framework” (Working
    Draft, November 28, 2018, revision).</li>
<li class="small-text">The Home Team consists of the Ministry of
    Home Affairs Headquarters, Singapore Police
    Force, Immigration and Checkpoints Authority,
    Home Team Academy, Internal Security
    Department, Singapore Civil Defence Force,
    Singapore Prison Service, Central Narcotics
    Bureau, Casino Regulatory Authority and
    the Singapore Corporation of Rehabilitative
    Enterprises.</li>
<li class="small-text">The Cylance Team, “Black Hat Attendees See AI as Double-Edged Sword”, August 1, 2017, accessed January 2, 2019, <a target="_blank" href="https://blogs.blackberry.com/en/2017/08/black-hat-attendees-see-ai-as-double-edged-sword">https://blogs.blackberry.com/en/2017/08/black-hat-attendees-see-ai-as-double-edged-sword</a>.</li>
<li class="small-text">Dan Patterson, “How Weaponized AI Creates  a New Breed of Cyber-Attacks”, <em>TechRepublic</em>,  August 16, 2018, accessed January 2, 2019,
    <a target="_blank" href="https://www.techrepublic.com/article/how-weaponized-ai-creates-a-new-breed-of-cyber-attacks/">https://www.techrepublic.com/article/how-weaponized-ai-creates-a-new-breed-of-cyber-attacks/.</a></li>
<li class="small-text">Marc Ph. Stoecklin, “DeepLocker: How AI Can Power A Stealthy New Breed of Malware”,<em>Security Intelligence</em>, August 8, 2018, accessed January 2, 2019, <a target="_blank" href="https://securityintelligence.com/deeplocker-how-ai-can-power-a-stealthy-new-breed-of-malware/">https://securityintelligence.com/deeplocker-how-ai-can-power-a-stealthy-new-breed-of-malware/.</a></li>
<li class="small-text">Infosec Institute, “How Criminals Can Exploit AI”, May 1, 2018, accessed December 26, 2018, <a target="_blank" href="https://resources.infosecinstitute.com/criminals-can-exploit-ai/#gref">https://resources.infosecinstitute.com/criminals-can-exploit-ai/#gref</a>.</li>
<li class="small-text">Oscar Schwartz, “You Thought Fake News Was Bad? Deep Fakes Are Where Truth Goes to Die”, <em>The Guardian</em>, November 12, 2018, accessed December 26, 2018, <a target="_blank" href="https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth">https://www.theguardian.com/technology/2018/nov/12/deep-fakes-fake-news-truth</a>.</li>
<li class="small-text">James Vincent, “Watch Jordan Peele Use AI To Make Barack Obama Deliver a PSA about Fake News”, The Verge, April 17, 2018, accessed December 26, 2018, <a target="_blank" href="https://www.theverge.com/tldr/2018/4/17/17247334/ai-fake-news-video-barack-obama-jordan-peele-buzzfeed">https://www.theverge.com/tldr/2018/4/17/17247334/ai-fake-news-video-barack-obama-jordan-peele-buzzfeed</a>.</li>
<li class="small-text">Kareem Ayoub and Kenneth Payne, “Strategy in the Age of Artificial Intelligence”, <em>Journal of Strategic Studies </em>39, no. 5 (November 2015):816.</li>
<li class="small-text">SparkCognition, “Deep Armor: Endpoint Protection, Built from AI”, accessed December 26, 2018, <a target="_blank" href="https://www.sparkcognition.com/products/">https://www.sparkcognition.com/products/</a>.</li>
<li class="small-text">Michell Christopher, “Artificial Intelligence in Thailand: How It Started and Where It’s Headed”, <em>OpenGov Asia</em>, July 12, 2018, accessed December 26, 2018, <a target="_blank" href="https://www.opengovasia.com/artificial-intelligence-in-thailand-how-it-started-and-where-its-headed">https://www.opengovasia.com/artificial-intelligence-in-thailand-how-it-started-and-where-its-headed</a>.</li>
<li class="small-text">Nurfilzah Rohaidi, “How Thailand Is Using AI for Cybersecurity”, <em>GovInsider</em>, November 27, 2018, accessed December 26, 2018, <a target="_blank" href="https://govinsider.asia/digital-gov/how-thailand-is-using-ai-for-cybersecurity/">https://govinsider.asia/digital-gov/how-thailand-is-using-ai-for-cybersecurity/</a>.</li>
<li class="small-text">Kai Shu, Amy Silva, Suhang Wang, Jiliang Tang and Huan Liu, “Fake News Detection on Social Media: A Data Mining Perspective”, <em>Sigkdd Explorations by Association for Computing Machinery </em>19, no. 1 (June 2017): 22–36, <a target="_blank" href="https://dl.acm.org/doi/10.1145/3137597.3137600">https://dl.acm.org/doi/10.1145/3137597.3137600</a>.</li>
<li class="small-text">Remarks by Mr S Iswaran, Minister for Communications and Information, at
    the Media Literacy Council’s Launch of the Fake News Campaign, November 2, 2018, accessed December 26, 2018, <a target="_blank" href="https://www.mci.gov.sg/pressroom/news-and-stories/pressroom/2018/11/remarks-by-minister-s-iswaran-at-the-media-literacy-council-launch-of-the-fake-news-campaign">https://www.mci.gov.sg/pressroom/news-and-stories/pressroom/2018/11/remarks-by-minister-s-iswaran-at-the-media-literacy-council-launch-of-the-fake-news-campaign</a>.</li>
<li class="small-text">Lianne Chia, “National Framework to Build Information and Media Literacy to be Launched in 2019: S Iswaran”, <em>CNA</em>, November 2, 2018, accessed December 26, 2018, <a target="_blank" href="https://www.channelnewsasia.com/news/singapore">https://www.channelnewsasia.com/singapore</a>.</li>
<li class="small-text">Infocomm Media Development Authority (IMDA), “New Council to Oversee Cyber Wellness, Media Literacy Initiatives”, November 3, 2017, accessed 26 December 2018, <a target="_blank" href="https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/archived/mda/press-releases/2012/new-council-to-oversee-cyber-wellness-media-literacy-initiatives">https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/archived/mda/press-releases/2012/new-council-to-oversee-cyber-wellness-media-literacy-initiatives</a>.</li>
</ol>




<br>
<br>	
<div class="back">
<a href="/ethos/">Back to Ethos Page</a>	
</div>